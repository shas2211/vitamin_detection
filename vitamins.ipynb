{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a75c4d-10aa-44d2-87b0-e1eee310c0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a2fc52-2d39-4c4c-b847-a42a89ec9bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##jst unzipped the test data\n",
    "local_zip='./test_data.zip'\n",
    "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4edcd3-f54b-4005-8365-154b3d1b128e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#unzipping the train data\n",
    "local_zip='./vitamins_detection.zip'\n",
    "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cb6a26d-a21f-4e87-85f5-c8d9687d76f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents of the base directory:\n",
      "['vitaminAtr', 'vitaminBtr', 'vitaminCtr', 'vitaminDtr', 'vitaminEtr']\n",
      "total training vitamin A images: 1644\n",
      "total training vitamin B images: 1704\n",
      "total training vitamin C images: 3103\n",
      "total training vitamin D images: 1104\n",
      "total training vitamin E images: 1414\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_dir='vitamins_detection'\n",
    "print(\"contents of the base directory:\")\n",
    "print(os.listdir(base_dir))\n",
    "vitaminA_train=os.path.join(base_dir,'vitaminAtr')\n",
    "vitaminB_train=os.path.join(base_dir,'vitaminBtr')\n",
    "vitaminC_train=os.path.join(base_dir,'vitaminCtr')\n",
    "vitaminD_train=os.path.join(base_dir,'vitaminDtr')\n",
    "vitaminE_train=os.path.join(base_dir,'vitaminEtr')\n",
    "print('total training vitamin A images:',len(os.listdir(vitaminA_train)))\n",
    "print('total training vitamin B images:',len(os.listdir(vitaminB_train)))\n",
    "print('total training vitamin C images:',len(os.listdir(vitaminC_train)))\n",
    "print('total training vitamin D images:',len(os.listdir(vitaminD_train)))\n",
    "print('total training vitamin E images:',len(os.listdir(vitaminE_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db9d6dc3-29d2-48f4-acaf-6bb489c98f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents of the validation directory\n",
      "['vitaminA', 'vitaminB', 'vitaminC', 'vitaminD', 'vitaminE']\n",
      "total validation vitamin A images: 52\n",
      "total validation vitamin B images: 42\n",
      "total validation vitamin C images: 62\n",
      "total validation vitamin D images: 28\n",
      "total validation vitamin E images: 40\n"
     ]
    }
   ],
   "source": [
    "#now spilt the data as train and validation,(new chatgpt)\n",
    "#totally forgot that they have give seperate dataset labeled as \"test\" taking that as validation\n",
    "validation_dir='test_data'\n",
    "print(\"contents of the validation directory\")\n",
    "print(os.listdir(validation_dir))\n",
    "vitaminA_validation=os.path.join(validation_dir,'vitaminA')\n",
    "vitaminB_validation=os.path.join(validation_dir,'vitaminB')\n",
    "vitaminC_validation=os.path.join(validation_dir,'vitaminC')\n",
    "vitaminD_validation=os.path.join(validation_dir,'vitaminD')\n",
    "vitaminE_validation=os.path.join(validation_dir,'vitaminE')\n",
    "print('total validation vitamin A images:',len(os.listdir(vitaminA_validation)))\n",
    "print('total validation vitamin B images:',len(os.listdir(vitaminB_validation)))\n",
    "print('total validation vitamin C images:',len(os.listdir(vitaminC_validation)))\n",
    "print('total validation vitamin D images:',len(os.listdir(vitaminD_validation)))\n",
    "print('total validation vitamin E images:',len(os.listdir(vitaminE_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af180c35-2ca1-4991-a5e9-7f2fbc821769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8969 images belonging to 5 classes.\n",
      "Found 224 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#we need to create two data generators one for image training and one for validation\n",
    "#declare the path to training dataset\n",
    "train_dir='vitamins_detection'\n",
    "#create a generator for training along with data augmentation,\n",
    "train_datagen=ImageDataGenerator(rescale=1/255,rotation_range=45,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\n",
    "#declare the path for validation\n",
    "valid_dir='test_data'\n",
    "valid_datagen=ImageDataGenerator(rescale=1/255)\n",
    "#create generator\n",
    "train_gen=train_datagen.flow_from_directory(train_dir,target_size=(224,224),class_mode='categorical',batch_size=15)\n",
    "valid_gen=valid_datagen.flow_from_directory(valid_dir,target_size=(224,224),class_mode='categorical',batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e514c868-87a9-4587-9054-44e93ec0590c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##model building! just copy and paste the import packages lines from skill wallet\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import softmax\n",
    "from keras.api._v2.keras import activations\n",
    "#now just import the vgg19 layer as said in skill wallet, \n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b5c3066-a84c-4bca-a9fe-cd6e0b5793e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#look the step initializing the model\n",
    "Image_size=[224,224]\n",
    "sol=VGG19(input_shape=Image_size+[3],weights='imagenet',include_top=False)\n",
    "#to freeze trainable =freeze, fix the base model as false\n",
    "sol.trainable = False\n",
    "\n",
    "y=Flatten()(sol.output)\n",
    "#the 19 layers itself is enough for feature detection, but let me add one more dense layer before the final output layer\n",
    "\n",
    "y=Dense(255,activation='relu')(y)\n",
    "final=Dense(5,activation='softmax')(y)\n",
    "#softmax for classification\n",
    "\n",
    "#declaring the model with input and output\n",
    "model=Model(sol.inputs,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce5a0185-bd36-4996-9697-71832dcdb5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 255)               6397695   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1280      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,423,359\n",
      "Trainable params: 6,398,975\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f17d30c-d438-4345-9d2a-bdf8b059c3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we just made the model now lets compile and then fit\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['Accuracy'])\n",
    "#optimizer like rmsprop can be used but as mentioned to use adam we use adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95df89b2-03cb-4abe-ac47-7d0d0dea164e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "598/598 [==============================] - 1406s 2s/step - loss: 1.3969 - Accuracy: 0.4847 - val_loss: 1.0066 - val_Accuracy: 0.6116\n",
      "Epoch 2/30\n",
      "598/598 [==============================] - 1463s 2s/step - loss: 1.1216 - Accuracy: 0.5511 - val_loss: 0.9850 - val_Accuracy: 0.6518\n",
      "Epoch 3/30\n",
      "598/598 [==============================] - 1401s 2s/step - loss: 1.0805 - Accuracy: 0.5671 - val_loss: 0.9953 - val_Accuracy: 0.6429\n",
      "Epoch 4/30\n",
      "598/598 [==============================] - 1985s 3s/step - loss: 1.0486 - Accuracy: 0.5841 - val_loss: 0.8069 - val_Accuracy: 0.7411\n",
      "Epoch 5/30\n",
      "598/598 [==============================] - 1980s 3s/step - loss: 1.0298 - Accuracy: 0.5896 - val_loss: 0.9629 - val_Accuracy: 0.6786\n",
      "Epoch 6/30\n",
      "598/598 [==============================] - 1370s 2s/step - loss: 1.0145 - Accuracy: 0.5939 - val_loss: 0.8178 - val_Accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "598/598 [==============================] - 1365s 2s/step - loss: 0.9921 - Accuracy: 0.6006 - val_loss: 0.9064 - val_Accuracy: 0.7009\n",
      "Epoch 8/30\n",
      "598/598 [==============================] - 2830s 5s/step - loss: 0.9709 - Accuracy: 0.6149 - val_loss: 0.9895 - val_Accuracy: 0.6830\n",
      "Epoch 9/30\n",
      "598/598 [==============================] - 3101s 5s/step - loss: 0.9644 - Accuracy: 0.6240 - val_loss: 0.8632 - val_Accuracy: 0.7098\n",
      "Epoch 10/30\n",
      "598/598 [==============================] - 2173s 4s/step - loss: 0.9572 - Accuracy: 0.6219 - val_loss: 0.9175 - val_Accuracy: 0.7098\n",
      "Epoch 11/30\n",
      "598/598 [==============================] - 1800s 3s/step - loss: 0.9489 - Accuracy: 0.6277 - val_loss: 0.8976 - val_Accuracy: 0.7321\n",
      "Epoch 12/30\n",
      "598/598 [==============================] - 2855s 5s/step - loss: 0.9438 - Accuracy: 0.6233 - val_loss: 0.9106 - val_Accuracy: 0.7366\n",
      "Epoch 13/30\n",
      "598/598 [==============================] - 1397s 2s/step - loss: 0.9409 - Accuracy: 0.6306 - val_loss: 0.8189 - val_Accuracy: 0.7232\n",
      "Epoch 14/30\n",
      "598/598 [==============================] - 1400s 2s/step - loss: 0.9306 - Accuracy: 0.6317 - val_loss: 1.0161 - val_Accuracy: 0.7098\n",
      "Epoch 15/30\n",
      "598/598 [==============================] - 1434s 2s/step - loss: 0.9148 - Accuracy: 0.6357 - val_loss: 0.8150 - val_Accuracy: 0.7366\n",
      "Epoch 16/30\n",
      "598/598 [==============================] - 1388s 2s/step - loss: 0.9160 - Accuracy: 0.6396 - val_loss: 0.8433 - val_Accuracy: 0.7321\n",
      "Epoch 17/30\n",
      "598/598 [==============================] - 1385s 2s/step - loss: 0.9194 - Accuracy: 0.6405 - val_loss: 0.8810 - val_Accuracy: 0.7679\n",
      "Epoch 18/30\n",
      "598/598 [==============================] - 1382s 2s/step - loss: 0.9113 - Accuracy: 0.6439 - val_loss: 0.8163 - val_Accuracy: 0.7545\n",
      "Epoch 19/30\n",
      "598/598 [==============================] - 2194s 4s/step - loss: 0.8961 - Accuracy: 0.6487 - val_loss: 0.8202 - val_Accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "598/598 [==============================] - 3091s 5s/step - loss: 0.9030 - Accuracy: 0.6423 - val_loss: 0.7696 - val_Accuracy: 0.7188\n",
      "Epoch 21/30\n",
      "598/598 [==============================] - 2288s 4s/step - loss: 0.8888 - Accuracy: 0.6511 - val_loss: 0.8262 - val_Accuracy: 0.7545\n",
      "Epoch 22/30\n",
      "598/598 [==============================] - 1372s 2s/step - loss: 0.8806 - Accuracy: 0.6536 - val_loss: 0.8731 - val_Accuracy: 0.7188\n",
      "Epoch 23/30\n",
      "598/598 [==============================] - 1373s 2s/step - loss: 0.8864 - Accuracy: 0.6561 - val_loss: 0.8522 - val_Accuracy: 0.7857\n",
      "Epoch 24/30\n",
      "598/598 [==============================] - 1374s 2s/step - loss: 0.8770 - Accuracy: 0.6589 - val_loss: 0.8123 - val_Accuracy: 0.7455\n",
      "Epoch 25/30\n",
      "598/598 [==============================] - 1377s 2s/step - loss: 0.8834 - Accuracy: 0.6548 - val_loss: 0.8294 - val_Accuracy: 0.7545\n",
      "Epoch 26/30\n",
      "598/598 [==============================] - 1372s 2s/step - loss: 0.8716 - Accuracy: 0.6573 - val_loss: 0.7858 - val_Accuracy: 0.7545\n",
      "Epoch 27/30\n",
      "598/598 [==============================] - 1541s 3s/step - loss: 0.8690 - Accuracy: 0.6622 - val_loss: 0.8392 - val_Accuracy: 0.7455\n",
      "Epoch 28/30\n",
      "598/598 [==============================] - 3071s 5s/step - loss: 0.8752 - Accuracy: 0.6567 - val_loss: 0.7465 - val_Accuracy: 0.7634\n",
      "Epoch 29/30\n",
      "598/598 [==============================] - 3108s 5s/step - loss: 0.8642 - Accuracy: 0.6625 - val_loss: 0.8394 - val_Accuracy: 0.7545\n",
      "Epoch 30/30\n",
      "598/598 [==============================] - 3028s 5s/step - loss: 0.8609 - Accuracy: 0.6667 - val_loss: 0.7965 - val_Accuracy: 0.7455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c69cabe850>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model and training it\n",
    "model.fit(train_gen,epochs=30,validation_data=valid_gen,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d62414e-2251-417d-b41a-f178636023a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1c69d104d10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b72cc216-8b83-413d-b890-6ea0f4f7fe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('vitamin_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed6fa203-8b8a-42d5-9083-433ae67bc89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('vitamin_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00bbea72-8ed1-418d-ba8b-b5a5c9e02528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "704e677e-9474-44c8-9ea3-2048a6fb433a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = 'carrots.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1fddfed3-c195-4e9b-9ce6-6c8183a9b495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 193ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68ea4e0a-f5d2-4192-9fc6-2404c9aaa7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9993622e-01, 0.0000000e+00, 6.3755899e-05, 0.0000000e+00,\n",
       "        6.3664985e-28]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ce037751-1bdf-488b-b915-857f86bd0a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_class_index = np.argmax(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8527bce9-b96b-4198-ae00-b1a8365e86b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "738c1284-2130-4b7a-bc27-4a75252a4c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your item has vitaminA\n"
     ]
    }
   ],
   "source": [
    "labels=[\"vitaminA\",\"vitaminB\",\"vitaminC\",\"vitaminD\",\"vitaminE\"]\n",
    "print(f'your item has {labels[predicted_class_index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e59c9-fa66-4a70-a984-cf6537c91790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
